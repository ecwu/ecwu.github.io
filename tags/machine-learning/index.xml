<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on ECWUUUUU</title><link>https://ecwuuuuu.com/tags/machine-learning/</link><description>Recent content in Machine Learning on ECWUUUUU</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 23 Jan 2022 14:24:00 +0800</lastBuildDate><atom:link href="https://ecwuuuuu.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>PyTorch Tutorial</title><link>https://ecwuuuuu.com/post/pytorch-tutorial/</link><pubDate>Fri, 05 Jan 2024 00:25:00 +0800</pubDate><guid>https://ecwuuuuu.com/post/pytorch-tutorial/</guid><description>&lt;blockquote&gt;
&lt;p&gt;A little bit of context&lt;/p&gt;
&lt;p&gt;This is the tutorial material I prepared in fall 2023, for people with basic foundation of machine learning to get hands-on PyTorch quickly.&lt;/p&gt;
&lt;p&gt;My idea behind the whole document is to teach the reader how to do full model training from the ground up and introduce each component alongside the process.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="introduction-to-pytorch"&gt;Introduction to PyTorch&lt;/h2&gt;
&lt;p&gt;&lt;figure&gt;&lt;img
 class="my-0 rounded-md"
 loading="lazy"
 decoding="async"
 fetchpriority="low"
 alt="PyTorch"
 src="https://pytorch.org/assets/images/logo-white.svg"
 &gt;&lt;/figure&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyTorch is an open-source deep learning framework that provides a flexible and dynamic approach to building and training neural networks.&lt;/li&gt;
&lt;li&gt;Its popularity and widespread adoption by the research and industry communities.&lt;/li&gt;
&lt;li&gt;PyTorch is widely known for its ease of use, Pythonic interface, and excellent support for research-oriented tasks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="key-technology"&gt;Key Technology&lt;/h3&gt;
&lt;h4 id="dynamic-computational-graph"&gt;Dynamic computational graph&lt;/h4&gt;
&lt;p&gt;A &lt;strong&gt;computational graph&lt;/strong&gt; represents the flow of data through a computational model in the form of a directed acyclic graph (DAG). It serves as a visual representation of the mathematical operations performed on input data to produce the desired output.&lt;/p&gt;</description></item><item><title>Sigmoid or Softmax for Binary Classification</title><link>https://ecwuuuuu.com/post/sigmoid-softmax-binary-class/</link><pubDate>Mon, 07 Jun 2021 13:06:14 +0800</pubDate><guid>https://ecwuuuuu.com/post/sigmoid-softmax-binary-class/</guid><description>&lt;p&gt;Recently, been asked a question on using neural networks for binary classification.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The output layer of the network can be &amp;hellip; &lt;strong&gt;One output neuron with sigmoid activation function&lt;/strong&gt; or &lt;strong&gt;Two neurons and then apply a softmax activation function&lt;/strong&gt;. But what is the difference between these two?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let start with the equations of the two functions.&lt;/p&gt;
&lt;p&gt;Sigmoid Activation Function
$$
S(x) = \frac{1}{ 1+e^{-x}}
$$&lt;/p&gt;
&lt;p&gt;We input the value of the last layer $x$, and we can get a value in the range 0 to 1 as shown in the figure. If the value is greater than 0.5, we consider the model output as one class, or the other class if the value is less than 0.5.
&lt;figure class="w-full"&gt;
 &lt;img src="https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg" class="rounded-lg"&gt;

 &lt;figcaption&gt;
 &lt;strong&gt;The logistic sigmoid function &lt;/strong&gt;
 
 &lt;a href="https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg"&gt;
 Wikimedia Commons
 &lt;/a&gt;
 &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;</description></item><item><title>My Past NLP Projects</title><link>https://ecwuuuuu.com/post/nlp/</link><pubDate>Fri, 07 May 2021 00:13:30 +0800</pubDate><guid>https://ecwuuuuu.com/post/nlp/</guid><description>&lt;p&gt;I started to learn NLP-related stuff in mid-2018. And gradually start to some serious research. My focus mainly on Natural Language Generation (NLG).&lt;/p&gt;
&lt;h2 id="beginning-semeval2019"&gt;Beginning: SemEval2019&lt;/h2&gt;
&lt;p&gt;By the end of 2018, members of the AI learning group &lt;span class="px-2 py-1 text-gray-700 bg-gray-300 bg-stripes bg-stripes-white dark:text-gray-400 dark:bg-slate-700 dark:bg-stripes-slate-900 rounded-md"&gt;Lead by &lt;a href="https://dst.uic.edu.cn/en/faculty/faculty.htm#/wfsu/en"&gt;Prof. Weifeng Su&lt;/a&gt;&lt;/span&gt; decide to take part in the SemEval 2019. To study and learning more about NLP.&lt;/p&gt;
&lt;p&gt;Our group chose task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval). Which the input text is users&amp;rsquo; tweets and we need to classify it.&lt;/p&gt;</description></item></channel></rss>